{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434dcf89-1cc0-4077-9c3e-d893f55838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, date\n",
    "import random, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import copy\n",
    "import gzip\n",
    "import pickle\n",
    "from scipy.stats import rankdata\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6ed42-d6a2-46de-9b8a-bc5994d96b1f",
   "metadata": {},
   "source": [
    "### single concept's citation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99ff28-b872-4777-8df2-8cfbd1a5031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "data_folder=\"data_concept_graph\"\n",
    "\n",
    "# Read all concepts together with time, citation information\n",
    "dynamic_concept_file=os.path.join(data_folder,\"full_dynamic_concept.parquet\")\n",
    "full_concepts_dynamic_data = pd.read_parquet(dynamic_concept_file)\n",
    "\n",
    "# Read all concepts from full_concepts_for_openalex.txt\n",
    "concepts_files = os.path.join(data_folder, 'full_domain_concepts.txt')\n",
    "with open(concepts_files, 'r') as file:\n",
    "    full_concepts = [concept.strip() for concept in file.readlines()]\n",
    "\n",
    "print(f\"Done, elapsed_time: {time.time() - time_start}\\n full_concepts_dynamic_data: {len(full_concepts_dynamic_data)};\\n full_concept: {len(full_concepts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610f570-ce15-4f5b-9bb3-1640bc0a7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_VERTICES=len(full_concepts)\n",
    "vertex_degree_cutoff=1\n",
    "years_delta=3\n",
    "min_edges=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a6454-4b41-4a62-ad2f-ace410365751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "years=[2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "day_origin = date(1990,1,1)\n",
    "all_concepts_df = pd.DataFrame({'v1': range(0, NUM_OF_VERTICES)})\n",
    "\n",
    "store_folder=\"data_for_features\"\n",
    "if not os.path.exists(store_folder):\n",
    "    os.makedirs(store_folder)\n",
    "\n",
    "start_time=time.time()\n",
    "for yy in years:  \n",
    "    print(f'Year: {yy}')\n",
    "    day_curr=(date(yy,12,31)- day_origin).days\n",
    "    columns_to_subtract = [f'c{i}' for i in range(2023, yy, -1)]\n",
    "    print(columns_to_subtract)\n",
    "    cols_to_sum = [f'c{i}' for i in range(yy, yy-years_delta, -1)]\n",
    "    print(cols_to_sum)\n",
    "    \n",
    "    dynamic_concepts=full_concepts_dynamic_data[full_concepts_dynamic_data['time']<=day_curr]\n",
    "    dynamic_concepts_df = dynamic_concepts.copy()\n",
    "    \n",
    "    dynamic_concepts_df[f'ct_{yy}'] = dynamic_concepts_df['ct'] - dynamic_concepts_df[columns_to_subtract].sum(axis=1)\n",
    "    \n",
    "    dynamic_concepts_df['ct_delta'] = dynamic_concepts_df[cols_to_sum].sum(axis=1)\n",
    "    \n",
    "    dynamic_concepts_df=dynamic_concepts_df[['v1', f'c{yy}', f'ct_{yy}', 'ct_delta']]\n",
    "    \n",
    "    dynamic_concepts_grouped = dynamic_concepts_df.groupby('v1').agg({f'c{yy}':'sum', f'ct_{yy}':'sum', 'ct_delta':'sum', 'v1':'size'}).rename(columns={'v1':f'num'}).reset_index()\n",
    "    \n",
    "    dynamic_concepts_grouped[f'c{yy}_m'] = dynamic_concepts_grouped[f'c{yy}'] / dynamic_concepts_grouped[f'num']\n",
    "    dynamic_concepts_grouped[f'ct_{yy}_m'] = dynamic_concepts_grouped[f'ct_{yy}'] / dynamic_concepts_grouped[f'num']\n",
    "    dynamic_concepts_grouped[f'ct_delta_m'] = dynamic_concepts_grouped['ct_delta'] / dynamic_concepts_grouped[f'num']\n",
    "     \n",
    "    \n",
    "    # Merge with all_concepts_df\n",
    "    dynamic_concepts_data = pd.merge(all_concepts_df, dynamic_concepts_grouped, on='v1', how='left')\n",
    "    dynamic_concepts_data.fillna(0, inplace=True) # Fill NaN values with 0\n",
    "    dynamic_concepts_data.sort_values(by='v1')\n",
    "    \n",
    "    data_file = os.path.join(store_folder, f\"concept_node_citation_data_{yy}.parquet\")\n",
    "    dynamic_concepts_data.to_parquet(data_file, compression='gzip')\n",
    "    print(f\"in {yy}; time: {time.time()-start_time}\\n\")\n",
    "    start_time=time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1147d2c-2fb7-4f12-a89f-e26d3a2d4689",
   "metadata": {},
   "source": [
    "### concept pair's citation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3dd3b-eb2a-474c-8665-9743514d55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "data_folder=\"data_concept_graph\"\n",
    "\n",
    "# Read all concepts together with time, citation information\n",
    "graph_file=os.path.join(data_folder,\"full_dynamic_graph.parquet\")\n",
    "full_edge_dynamic_data = pd.read_parquet(graph_file)\n",
    "\n",
    "print(f\"Done, elapsed_time: {time.time() - time_start}\\n full_edge_dynamic_data: {len(full_edge_dynamic_data)};\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fc43-a136-4959-8b29-1717eca77bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "years=[2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "day_origin = date(1990,1,1)\n",
    " \n",
    "store_folder=\"data_for_features\"\n",
    "start_time=time.time()\n",
    "for yy in years:  \n",
    "    print(f'Year: {yy}')\n",
    "    day_curr=(date(yy,12,31)- day_origin).days\n",
    "    columns_to_subtract = [f'c{i}' for i in range(2023, yy, -1)]\n",
    "    print(columns_to_subtract)\n",
    "    cols_to_sum = [f'c{i}' for i in range(yy, yy-years_delta, -1)]\n",
    "    print(cols_to_sum)\n",
    "    \n",
    "    dynamic_pairs=full_edge_dynamic_data[full_edge_dynamic_data['time']<=day_curr]\n",
    "    dynamic_pairs_df = dynamic_pairs.copy()\n",
    "    \n",
    "    dynamic_pairs_df[f'ct_{yy}'] = dynamic_pairs_df['ct'] - dynamic_pairs_df[columns_to_subtract].sum(axis=1)\n",
    "    \n",
    "    dynamic_pairs_df['ct_delta'] = dynamic_pairs_df[cols_to_sum].sum(axis=1)\n",
    "    \n",
    "    dynamic_pairs_df=dynamic_pairs_df[['v1', 'v2', f'c{yy}', f'ct_{yy}', 'ct_delta']]\n",
    "    \n",
    "    dynamic_pairs_grouped = dynamic_pairs_df.groupby(['v1','v2']).agg({f'c{yy}':'sum', f'ct_{yy}':'sum', 'ct_delta':'sum', 'v1':'size'}).rename(columns={'v1':f'num'}).reset_index()\n",
    "    \n",
    "    dynamic_pairs_grouped[f'c{yy}_m'] = dynamic_pairs_grouped[f'c{yy}'] / dynamic_pairs_grouped[f'num']\n",
    "    dynamic_pairs_grouped[f'ct_{yy}_m'] = dynamic_pairs_grouped[f'ct_{yy}'] / dynamic_pairs_grouped[f'num']\n",
    "    dynamic_pairs_grouped[f'ct_delta_m'] = dynamic_pairs_grouped['ct_delta'] / dynamic_pairs_grouped[f'num']\n",
    "    \n",
    "    data_file = os.path.join(store_folder, f\"concept_pair_citation_data_{yy}.parquet\")\n",
    "    dynamic_pairs_grouped.to_parquet(data_file, compression='gzip')\n",
    "    print(f\"in {yy}; time: {time.time()-start_time}\\n\")\n",
    "    start_time=time.time()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl_semnet",
   "language": "python",
   "name": "asl_semnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

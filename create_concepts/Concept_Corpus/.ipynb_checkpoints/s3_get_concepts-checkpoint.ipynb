{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17001bd9-da10-4fe7-a3d4-9c5174944296",
   "metadata": {},
   "source": [
    "### load all the processed preprint papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebad34-ea44-4336-8665-ceabec4c5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "if os.path.exists('all_paper_info_lists.pkl'):\n",
    "    # open the existing pickle file for reading\n",
    "    with open('all_paper_info_lists.pkl', 'rb') as f:\n",
    "        all_paper_lists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4475b-b22e-417d-8f74-64045ea27f90",
   "metadata": {},
   "source": [
    "### put title and abstract together, store in to string list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd905ebe-207c-4f63-b869-5e4434343ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_article_string(article):\n",
    "    \n",
    "    curr_title=article[1] #'title'\n",
    "    curr_abstract=article[2] #'abstract'\n",
    "    \n",
    "    replace_pairs=[['\\n',' '],['-',' '],[' \\\" a','oa'],['\\\" a','ae'],['\\\"a','ae'],[' \\\" o','oe'],['\\\" o','oe'],['\\\"o','oe'],[' \\\" u','ue'],\n",
    "                   ['\\\" u','ue'],['\\\"u','ue'],[' \\' a','a'],[' \\' e','e'],[' \\' o','o'],[\"\\' \", \"\"],[\"\\'\", \"\"],['  ',' '],['  ',' ']]\n",
    "    \n",
    "    article_string=(curr_title +' '+ curr_abstract).lower()\n",
    "    \n",
    "    for rep_pair in replace_pairs:\n",
    "        #print(rep_pair)\n",
    "        \n",
    "        article_string=article_string.replace(rep_pair[0],rep_pair[1])\n",
    "        #print(article_string)\n",
    "        #print('\\n')\n",
    "    \n",
    "    return article_string\n",
    "\n",
    "def get_all_paper_strings(article_lists):\n",
    "\n",
    "    if os.path.exists('all_paper_string_lists.pkl'):\n",
    "        with open(\"all_paper_string_lists.pkl\", \"rb\") as f:\n",
    "            all_paper_strings = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        all_paper_strings=[]\n",
    "        cc=0\n",
    "        for id_of_paper in range(len(article_lists)):\n",
    "            cc+=1\n",
    "            if (cc%300000)==0:\n",
    "                print(str(cc)+'/'+str(len(article_lists)))\n",
    "\n",
    "            all_paper_strings.append(get_single_article_string(article_lists[id_of_paper]))\n",
    "\n",
    "        with open(\"all_paper_string_lists.pkl\", \"wb\") as f:\n",
    "            pickle.dump(all_paper_strings, f)\n",
    "    \n",
    "    return all_paper_strings\n",
    "\n",
    "\n",
    "\n",
    "all_article_strings=get_all_paper_strings(all_paper_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3b05e-a8eb-4e1a-a4a6-273f702eac16",
   "metadata": {},
   "source": [
    "### Get Concepts from RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845be865-8db6-4956-ade5-918b191954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from rake_nltk import Metric, Rake\n",
    "from collections import Counter\n",
    "\n",
    "starting_time = time.time()\n",
    " \n",
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "num_of_abstracts=len(all_paper_lists)\n",
    "\n",
    "personal_stop_list=['presents','us','show','one','two','three','describes','new','approach','many','introduces','http','also','whose', 'prove','select ','take']\n",
    "\n",
    "nltk_stop_list=nltk.corpus.stopwords.words('english')\n",
    "full_stop_list=nltk_stop_list + personal_stop_list\n",
    "\n",
    "\n",
    "all_concepts_from_rake=[]\n",
    "cc=0\n",
    "for id_of_abstract in range(num_of_abstracts):\n",
    "    cc+=1\n",
    "    if (cc%100000)==0:\n",
    "        print(str(cc)+'/'+str(num_of_abstracts))\n",
    "    \n",
    "            \n",
    "    single_string = get_single_article_string(all_paper_lists[id_of_abstract])\n",
    "    \n",
    "    r = Rake(stopwords=full_stop_list, ranking_metric=Metric.WORD_DEGREE, min_length=2, include_repeated_phrases=False)\n",
    "\n",
    "    r.extract_keywords_from_text(single_string)\n",
    "    ll=r.get_ranked_phrases_with_scores()\n",
    "    \n",
    "    all_concepts_from_rake.extend(ll)\n",
    "\n",
    "\n",
    "with open(\"all_concepts_from_rake.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(all_concepts_from_rake, output_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d5a11-4106-42e6-aedc-4b2a02c34b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl_semnet",
   "language": "python",
   "name": "asl_semnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
